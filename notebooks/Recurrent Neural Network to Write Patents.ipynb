{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction: Writing Patents Using a Recurrent Neural Network\n",
    "\n",
    "The purpose of this notebook is to develop a recurrent neural network which can be used to write patent abstracts. Although this is mostly meant as a simple example, the idea of recurrent neural networks is powerful and can be usde for real purposes such as generating text similar to a corpus, machine translation, and supervised learning tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "BATCH_SIZE = 512\n",
    "CHUNK_SIZE = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "556"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "data = []\n",
    "\n",
    "with open('../data/found_tech_patents.ndjson', 'rt') as fin:\n",
    "    data = [json.loads(l) for l in fin]\n",
    "    \n",
    "data = [r for r in data if r[1] is not None]\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens = [len(x[1]) for x in data]\n",
    "min(lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Recurrent neural network-based fuzzy logic system and method ',\n",
       " 'A recurrent, neural network-based fuzzy logic system includes in a rule base layer and a membership function layer neurons which each have a recurrent architecture with an output-to-input feedback path including a time delay element and a neural weight. Further included is a recurrent, neural network-based fuzzy logic rule generator wherein a neural network receives and fuzzifies input data and provides data corresponding to fuzzy logic membership functions and recurrent fuzzy logic rules.')"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][0], data[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstracts = [d[1] for d in data]\n",
    "titles = [d[0] for d in data]\n",
    "\n",
    "chars = []\n",
    "for abstract in abstracts:\n",
    "    for ch in abstract:\n",
    "        chars.append(ch)\n",
    "        \n",
    "chars = set(chars)\n",
    "len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47, 'a')"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_idx = {char: idx for idx, char in enumerate(chars)}\n",
    "idx_to_char = {idx: char for char, idx in char_to_idx.items()}\n",
    "char_to_idx['a'], idx_to_char[47]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Input, Model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_rnn_model(num_chars, num_layers, num_nodes = 512, dropout = 0.1):\n",
    "    # Take in a sequence of one-hot encoded characters\n",
    "    input_layer = Input(shape = (None, num_chars), name = 'input')\n",
    "    prev = input_layer\n",
    "    \n",
    "    # Add an LSTM cell for each layer\n",
    "    for i in range(num_layers):\n",
    "        lstm = LSTM(num_nodes, return_sequences = True, name = f'lstm_layer_{i}')(prev)\n",
    "        if dropout:\n",
    "            prev = Dropout(dropout)(lstm)\n",
    "        else:\n",
    "            prev = lstm\n",
    "            \n",
    "    # For each time step find the most likely character - one time step considers up to current character\n",
    "    # Time Distributed applies same layer to all time steps (first dimension)\n",
    "    dense = TimeDistributed(Dense(num_chars, name = 'dense',\n",
    "                             activation = 'softmax'))(prev)\n",
    "    model = Model(inputs = [input_layer], outputs = [dense])\n",
    "    \n",
    "    # Compile with categorical loss\n",
    "    model.compile(loss = 'categorical_crossentropy', \n",
    "                  optimizer = RMSprop(lr=0.01), \n",
    "                  metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, None, 101)         0         \n",
      "_________________________________________________________________\n",
      "lstm_layer_0 (LSTM)          (None, None, 512)         1257472   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, None, 512)         0         \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, None, 101)         51813     \n",
      "=================================================================\n",
      "Total params: 1,309,285\n",
      "Trainable params: 1,309,285\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = char_rnn_model(len(chars), 1)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A method for facilitating the avoidance of a vehicle collision with an object includes the following steps: a) providing an environment for generating training examples, b) evolving a good driver using a visual input, c) evolving a crash predictor using a visual input, and d) outputting a warning signal.']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.sample(abstracts, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def data_generator(text, char_to_idx, batch_size, chunk_size):\n",
    "    X = np.zeros((batch_size, chunk_size, len(char_to_idx)))\n",
    "    y = np.zeros((batch_size, chunk_size, len(char_to_idx)))\n",
    "    \n",
    "    chunk_size_original = chunk_size\n",
    "    \n",
    "    # Generator yields samples\n",
    "    while True:\n",
    "        # Batch size is number of samples to use\n",
    "        for row in range(batch_size):\n",
    "            \n",
    "            # Choose a random abstract\n",
    "            sample = random.sample(text, 1)[0]\n",
    "            \n",
    "            # Choose a random starting index\n",
    "            idx = random.randrange(len(sample) - chunk_size - 1)\n",
    "\n",
    "            # Empty array to hold a chunk, chunk size is number of characters to extract\n",
    "            chunk = np.zeros((chunk_size + 1, len(char_to_idx)))\n",
    "            \n",
    "            # Need to find one more than chunk size to make labels\n",
    "            for i in range(chunk_size + 1):\n",
    "                chunk[i, char_to_idx[sample[idx + i]]] = 1\n",
    "                \n",
    "            # Features are all characters except for last\n",
    "            X[row, :, :] = chunk[:chunk_size]\n",
    "            # Labels are all characters except for first\n",
    "            y[row, :, :] = chunk[1:]\n",
    "            \n",
    "        yield X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs, ys = next(data_generator(abstracts, char_to_idx, 512, chunk_size = 80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 80, 101)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 101)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = Xs[1]\n",
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a technical system is provided. In the method a reinforcing learning method and '"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = []\n",
    "\n",
    "for row in sample:\n",
    "    x.append(idx_to_char[np.argmax(row)])\n",
    "''.join(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a technical system is provided. In the method a reinforcing learning method and '"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = []\n",
    "\n",
    "for row in sample:\n",
    "    y.append(idx_to_char[np.argmax(row)])\n",
    "''.join(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The label is a shifted forward version of the features. At each feature, we are teaching the network to predict the next character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [EarlyStopping(monitor = 'loss', min_delta = 0.03, patience = 5),\n",
    "             ModelCheckpoint(filepath = '../models/first_rnn.h5', save_best_only=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "448997"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import chain\n",
    "all_text = list(chain(*abstracts))\n",
    "len(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      " - 6s - loss: 1.0848 - acc: 0.6970\n",
      "Epoch 2/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/callbacks.py:432: RuntimeWarning: Can save best model only with val_loss available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 5s - loss: 1.1511 - acc: 0.6917\n",
      "Epoch 3/40\n",
      " - 5s - loss: 0.9657 - acc: 0.7186\n",
      "Epoch 4/40\n",
      " - 5s - loss: 0.9456 - acc: 0.7241\n",
      "Epoch 5/40\n",
      " - 5s - loss: 1.0393 - acc: 0.7160\n",
      "Epoch 6/40\n",
      " - 5s - loss: 1.0146 - acc: 0.7212\n",
      "Epoch 7/40\n",
      " - 5s - loss: 0.8862 - acc: 0.7406\n",
      "Epoch 8/40\n",
      " - 5s - loss: 0.9203 - acc: 0.7378\n",
      "Epoch 9/40\n",
      " - 5s - loss: 0.8996 - acc: 0.7445\n",
      "Epoch 10/40\n",
      " - 5s - loss: 1.0287 - acc: 0.7291\n",
      "Epoch 11/40\n",
      " - 5s - loss: 0.8931 - acc: 0.7495\n",
      "Epoch 12/40\n",
      " - 5s - loss: 0.8735 - acc: 0.7535\n"
     ]
    }
   ],
   "source": [
    "train_gen = data_generator(abstracts, char_to_idx, 256, chunk_size=CHUNK_SIZE)\n",
    "\n",
    "h = model.fit_generator(generator=train_gen, epochs = 40, callbacks = callbacks,\n",
    "                        steps_per_epoch = 2 * len(all_text) / (BATCH_SIZE * CHUNK_SIZE),\n",
    "                        verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.randint(0, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.randrange(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "def generate_output(model, text, start_index = 2, diversity = None, amount = 400):\n",
    "    \n",
    "    if start_index is None:\n",
    "        start_index = random.randint(0, CHUNK_SIZE)\n",
    "        \n",
    "    sample = random.sample(text, 1)[0]\n",
    "    generated = sample[start_index: start_index + CHUNK_SIZE]\n",
    "    yield generated + '#'\n",
    "    \n",
    "    for i in range(amount):\n",
    "        x = np.zeros((1, len(generated), len(chars)))\n",
    "        for t, char in enumerate(generated):\n",
    "            x[0, t, char_to_idx[char]] = 1\n",
    "            \n",
    "        preds = model.predict(x, verbose = 0)[0]\n",
    "    \n",
    "        if diversity is None:\n",
    "            next_index = np.argmax(preds[len(generated) - 1])\n",
    "            \n",
    "        else:\n",
    "            preds = np.array(preds[len(generated) - 1]).astype(np.float64)\n",
    "            preds = np.log(preds) / diversity\n",
    "            exp_preds = np.exp(preds)\n",
    "            preds = exp_preds / np.sum(exp_preds)\n",
    "            probas = np.random.multinomial(1, preds, 1)\n",
    "            next_index = np.argmax(preds)\n",
    "            \n",
    "        next_char = idx_to_char[next_index]\n",
    "        yield next_char\n",
    "        \n",
    "        generated += next_char\n",
    "    return generated\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-destructive testing device for pipes is provided. The device extracts inform#ation in a self-organizing manner based on the first and second sensors and an indication of the sensors and a second neural network to produce a prediction of the control system (116). The invention units can be trained to a control action (12) and a sequence of sumples of the sequence of speech recognition in a subject comprising: (a) measuring at least one of the physical neural network (RNN) i"
     ]
    }
   ],
   "source": [
    "for ch in generate_output(model, abstracts):\n",
    "    sys.stdout.write(ch)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning system is provided, which includes network storage means for storing a #neuron in a controller in the sequence of words in an individual and control subjective the acoustic signal and an input signal with a neural network to produce a prediction of the control subject to be transmits and the second state variables and the second state variables and the second state variables and the second state variables and the second state variables and the second state variables a"
     ]
    }
   ],
   "source": [
    "for ch in generate_output(model, abstracts):\n",
    "    sys.stdout.write(ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "In this notebook, we got a small glimpse at the abilities of recurrent neural networks. Using just a few thousands patents and a basic neural network, we were able to teach a machine to produce reasonable outputs of patent abstracts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_p36]",
   "language": "python",
   "name": "conda-env-tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
