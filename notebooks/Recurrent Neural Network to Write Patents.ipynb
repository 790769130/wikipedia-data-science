{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction: Writing Patents Using a Recurrent Neural Network\n",
    "\n",
    "The purpose of this notebook is to develop a recurrent neural network which can be used to write patent abstracts. Although this is mostly meant as a simple example, the idea of recurrent neural networks is powerful and can be usde for real purposes such as generating text similar to a corpus, machine translation, and supervised learning tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "BATCH_SIZE = 512\n",
    "CHUNK_SIZE = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "556"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "data = []\n",
    "\n",
    "with open('../data/found_tech_patents.ndjson', 'rt') as fin:\n",
    "    data = [json.loads(l) for l in fin]\n",
    "    \n",
    "data = [r for r in data if r[1] is not None]\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens = [len(x[1]) for x in data]\n",
    "min(lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Recurrent neural network-based fuzzy logic system and method ',\n",
       " 'A recurrent, neural network-based fuzzy logic system includes in a rule base layer and a membership function layer neurons which each have a recurrent architecture with an output-to-input feedback path including a time delay element and a neural weight. Further included is a recurrent, neural network-based fuzzy logic rule generator wherein a neural network receives and fuzzifies input data and provides data corresponding to fuzzy logic membership functions and recurrent fuzzy logic rules.')"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][0], data[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstracts = [d[1] for d in data]\n",
    "titles = [d[0] for d in data]\n",
    "\n",
    "chars = []\n",
    "for abstract in abstracts:\n",
    "    for ch in abstract:\n",
    "        chars.append(ch)\n",
    "        \n",
    "chars = set(chars)\n",
    "len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47, 'a')"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_idx = {char: idx for idx, char in enumerate(chars)}\n",
    "idx_to_char = {idx: char for char, idx in char_to_idx.items()}\n",
    "char_to_idx['a'], idx_to_char[47]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Input, Model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_rnn_model(num_chars, num_layers, num_nodes = 512, dropout = 0.1):\n",
    "    # Take in a sequence of one-hot encoded characters\n",
    "    input_layer = Input(shape = (None, num_chars), name = 'input')\n",
    "    prev = input_layer\n",
    "    \n",
    "    # Add an LSTM cell for each layer\n",
    "    for i in range(num_layers):\n",
    "        lstm = LSTM(num_nodes, return_sequences = True, name = f'lstm_layer_{i}')(prev)\n",
    "        if dropout:\n",
    "            prev = Dropout(dropout)(lstm)\n",
    "        else:\n",
    "            prev = lstm\n",
    "            \n",
    "    # For each time step find the most likely character - one time step considers up to current character\n",
    "    # Time Distributed applies same layer to all time steps (first dimension)\n",
    "    dense = TimeDistributed(Dense(num_chars, name = 'dense',\n",
    "                             activation = 'softmax'))(prev)\n",
    "    model = Model(inputs = [input_layer], outputs = [dense])\n",
    "    \n",
    "    # Compile with categorical loss\n",
    "    model.compile(loss = 'categorical_crossentropy', \n",
    "                  optimizer = RMSprop(lr=0.01), \n",
    "                  metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, None, 101)         0         \n",
      "_________________________________________________________________\n",
      "lstm_layer_0 (LSTM)          (None, None, 512)         1257472   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, None, 512)         0         \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, None, 101)         51813     \n",
      "=================================================================\n",
      "Total params: 1,309,285\n",
      "Trainable params: 1,309,285\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = char_rnn_model(len(chars), 1)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A method for facilitating the avoidance of a vehicle collision with an object includes the following steps: a) providing an environment for generating training examples, b) evolving a good driver using a visual input, c) evolving a crash predictor using a visual input, and d) outputting a warning signal.']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.sample(abstracts, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def data_generator(text, char_to_idx, batch_size, chunk_size):\n",
    "    X = np.zeros((batch_size, chunk_size, len(char_to_idx)))\n",
    "    y = np.zeros((batch_size, chunk_size, len(char_to_idx)))\n",
    "    \n",
    "    chunk_size_original = chunk_size\n",
    "    \n",
    "    # Generator yields samples\n",
    "    while True:\n",
    "        # Batch size is number of samples to use\n",
    "        for row in range(batch_size):\n",
    "            \n",
    "            # Choose a random abstract\n",
    "            sample = random.sample(text, 1)[0]\n",
    "            \n",
    "            # Choose a random starting index\n",
    "            idx = random.randrange(len(sample) - chunk_size - 1)\n",
    "\n",
    "            # Empty array to hold a chunk, chunk size is number of characters to extract\n",
    "            chunk = np.zeros((chunk_size + 1, len(char_to_idx)))\n",
    "            \n",
    "            # Need to find one more than chunk size to make labels\n",
    "            for i in range(chunk_size + 1):\n",
    "                chunk[i, char_to_idx[sample[idx + i]]] = 1\n",
    "                \n",
    "            # Features are all characters except for last\n",
    "            X[row, :, :] = chunk[:chunk_size]\n",
    "            # Labels are all characters except for first\n",
    "            y[row, :, :] = chunk[1:]\n",
    "            \n",
    "        yield X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs, ys = next(data_generator(abstracts, char_to_idx, 512, chunk_size = 80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 80, 101)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 101)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = Xs[1]\n",
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a technical system is provided. In the method a reinforcing learning method and '"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = []\n",
    "\n",
    "for row in sample:\n",
    "    x.append(idx_to_char[np.argmax(row)])\n",
    "''.join(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a technical system is provided. In the method a reinforcing learning method and '"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = []\n",
    "\n",
    "for row in sample:\n",
    "    y.append(idx_to_char[np.argmax(row)])\n",
    "''.join(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The label is a shifted forward version of the features. At each feature, we are teaching the network to predict the next character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [EarlyStopping(monitor = 'loss', min_delta = 0.03, patience = 5),\n",
    "             ModelCheckpoint(filepath = '../models/first_rnn.h5', save_best_only=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "448997"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import chain\n",
    "all_text = list(chain(*abstracts))\n",
    "len(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      " - 6s - loss: 1.0848 - acc: 0.6970\n",
      "Epoch 2/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/callbacks.py:432: RuntimeWarning: Can save best model only with val_loss available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 5s - loss: 1.1511 - acc: 0.6917\n",
      "Epoch 3/40\n",
      " - 5s - loss: 0.9657 - acc: 0.7186\n",
      "Epoch 4/40\n",
      " - 5s - loss: 0.9456 - acc: 0.7241\n",
      "Epoch 5/40\n",
      " - 5s - loss: 1.0393 - acc: 0.7160\n",
      "Epoch 6/40\n",
      " - 5s - loss: 1.0146 - acc: 0.7212\n",
      "Epoch 7/40\n",
      " - 5s - loss: 0.8862 - acc: 0.7406\n",
      "Epoch 8/40\n",
      " - 5s - loss: 0.9203 - acc: 0.7378\n",
      "Epoch 9/40\n",
      " - 5s - loss: 0.8996 - acc: 0.7445\n",
      "Epoch 10/40\n",
      " - 5s - loss: 1.0287 - acc: 0.7291\n",
      "Epoch 11/40\n",
      " - 5s - loss: 0.8931 - acc: 0.7495\n",
      "Epoch 12/40\n",
      " - 5s - loss: 0.8735 - acc: 0.7535\n"
     ]
    }
   ],
   "source": [
    "train_gen = data_generator(abstracts, char_to_idx, 256, chunk_size=CHUNK_SIZE)\n",
    "\n",
    "h = model.fit_generator(generator=train_gen, epochs = 40, callbacks = callbacks,\n",
    "                        steps_per_epoch = 2 * len(all_text) / (BATCH_SIZE * CHUNK_SIZE),\n",
    "                        verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.randint(0, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.randrange(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "def generate_output(model, text, start_index = 2, diversity = None, amount = 400):\n",
    "    \n",
    "    if start_index is None:\n",
    "        start_index = random.randint(0, CHUNK_SIZE)\n",
    "        \n",
    "    sample = random.sample(text, 1)[0]\n",
    "    generated = sample[start_index: start_index + CHUNK_SIZE]\n",
    "    yield generated + '#'\n",
    "    \n",
    "    for i in range(amount):\n",
    "        x = np.zeros((1, len(generated), len(chars)))\n",
    "        for t, char in enumerate(generated):\n",
    "            x[0, t, char_to_idx[char]] = 1\n",
    "            \n",
    "        preds = model.predict(x, verbose = 0)[0]\n",
    "    \n",
    "        if diversity is None:\n",
    "            next_index = np.argmax(preds[len(generated) - 1])\n",
    "            \n",
    "        else:\n",
    "            preds = np.array(preds[len(generated) - 1]).astype(np.float64)\n",
    "            preds = np.log(preds) / diversity\n",
    "            exp_preds = np.exp(preds)\n",
    "            preds = exp_preds / np.sum(exp_preds)\n",
    "            probas = np.random.multinomial(1, preds, 1)\n",
    "            next_index = np.argmax(preds)\n",
    "            \n",
    "        next_char = idx_to_char[next_index]\n",
    "        yield next_char\n",
    "        \n",
    "        generated += next_char\n",
    "    return generated\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lse oximetry is improved through classification of plethysmographic signals by p#rocessing the actions based on the first and second sensors and an indication of the sensors to determine the at least one of the predicted time series pattern storage networks to provide a refined probability of the control subject to be trained to the action i"
     ]
    }
   ],
   "source": [
    "for ch in generate_output(model, abstracts):\n",
    "    sys.stdout.write(ch)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharacterTable(object):\n",
    "    \"\"\"Given a set of characters:\n",
    "    + Encode them to a one hot integer representation\n",
    "    + Decode the one hot integer representation to their character output\n",
    "    + Decode a vector of probabilities to their character output\n",
    "    \"\"\"\n",
    "    def __init__(self, chars):\n",
    "        \"\"\"Initialize character table.\n",
    "        # Arguments\n",
    "            chars: Characters that can appear in the input.\n",
    "        \"\"\"\n",
    "        self.chars = sorted(set(chars))\n",
    "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
    "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
    "\n",
    "    def encode(self, C, num_rows):\n",
    "        \"\"\"One hot encode given string C.\n",
    "        # Arguments\n",
    "            num_rows: Number of rows in the returned one hot encoding. This is\n",
    "                used to keep the # of rows for each data the same.\n",
    "        \"\"\"\n",
    "        x = np.zeros((num_rows + 1, len(self.chars)))\n",
    "        for i, c in enumerate(C):\n",
    "            x[i, self.char_indices[c]] = 1\n",
    "        return x\n",
    "\n",
    "    def decode(self, x, calc_argmax=True):\n",
    "        if calc_argmax:\n",
    "            x = x.argmax(axis=-1)\n",
    "        return ''.join(self.indices_char[x] for x in x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3444"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens = [len(a) for a in abstracts]\n",
    "max(lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctable = CharacterTable(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A recurrent, neural network-based fuzzy logic system includes in a rule base layer and a membership function layer neurons which each have a recurrent architecture with an output-to-input feedback path including a time delay element and a neural weight. Further included is a recurrent, neural network-based fuzzy logic rule generator wherein a neural network receives and fuzzifies input data and provides data corresponding to fuzzy logic membership functions and recurrent fuzzy logic rules.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       '"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = ctable.encode(abstracts[0], max(lens))\n",
    "ctable.decode(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ',\n",
       " '\"',\n",
       " '#',\n",
       " '%',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '+',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " ':',\n",
       " ';',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'F',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'J',\n",
       " 'K',\n",
       " 'L',\n",
       " 'M',\n",
       " 'N',\n",
       " 'O',\n",
       " 'P',\n",
       " 'Q',\n",
       " 'R',\n",
       " 'S',\n",
       " 'T',\n",
       " 'U',\n",
       " 'V',\n",
       " 'W',\n",
       " 'X',\n",
       " 'Y',\n",
       " 'Z',\n",
       " '[',\n",
       " ']',\n",
       " '_',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z',\n",
       " '{',\n",
       " '|',\n",
       " '}',\n",
       " '×',\n",
       " 'Δ',\n",
       " 'α',\n",
       " 'γ',\n",
       " 'η',\n",
       " 'θ',\n",
       " 'κ',\n",
       " 'μ',\n",
       " '—',\n",
       " '‘',\n",
       " '’',\n",
       " '“',\n",
       " '”',\n",
       " '′',\n",
       " '→',\n",
       " '≈',\n",
       " '≦',\n",
       " '≧'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstracts = [r[1] for r in data]\n",
    "titles = [r[0] for r in data]\n",
    "\n",
    "chars = []\n",
    "for abstract in abstracts:\n",
    "    if abstract is not None:\n",
    "        for ch in abstract:\n",
    "            chars.append(ch)\n",
    "        \n",
    "chars = set(chars)\n",
    "chars\n",
    "# chars = set(ch for abtract in abstracts for ch in abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sludge settling index Soft tissue measurements from t-s Fuzzy Neural Network  199\n"
     ]
    }
   ],
   "source": [
    "c = '泥'\n",
    "\n",
    "for i, a in enumerate(abstracts):\n",
    "    if c in a:\n",
    "        print(titles[i], i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1540"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_p36]",
   "language": "python",
   "name": "conda-env-tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
