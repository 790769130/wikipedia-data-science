{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T00:44:22.792507Z",
     "start_time": "2018-10-15T00:44:22.596333Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing import utils\n",
    "from keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T00:44:24.438897Z",
     "start_time": "2018-10-15T00:44:24.434957Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T00:44:27.165006Z",
     "start_time": "2018-10-15T00:44:26.922953Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6382"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from itertools import chain\n",
    "import os\n",
    "\n",
    "data = []\n",
    "\n",
    "for file in os.listdir('../data/patents_parsed/'):\n",
    "    with open(f'../data/patents_parsed/{file}', 'rt') as fin:\n",
    "        data.append([json.loads(l) for l in fin])\n",
    "\n",
    "data = list(chain(*data))\n",
    "data = [r for r in data if r[0] is not None]\n",
    "data = [r for r in data if len(r[0]) >= 200]\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find set of unique characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T00:44:50.664053Z",
     "start_time": "2018-10-15T00:44:48.171380Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstracts = [d[0] for d in data]\n",
    "titles = [d[1] for d in data]\n",
    "\n",
    "chars = []\n",
    "for abstract in abstracts:\n",
    "    for ch in abstract:\n",
    "        chars.append(ch)\n",
    "\n",
    "chars = set(chars)\n",
    "len(chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize into integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T00:49:30.122765Z",
     "start_time": "2018-10-15T00:49:29.492266Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(num_words = 50000, lower=False, filters='!\"#$%&(),:;@[\\\\]^_`{|}~\\t\\n')\n",
    "tokenizer.fit_on_texts(abstracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T00:49:37.731560Z",
     "start_time": "2018-10-15T00:49:37.715974Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 53486),\n",
       " ('a', 36620),\n",
       " ('of', 32257),\n",
       " ('and', 23437),\n",
       " ('to', 21992),\n",
       " ('for', 12402),\n",
       " ('is', 11831),\n",
       " ('in', 10770),\n",
       " ('The', 9716),\n",
       " ('an', 8311)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wc = tokenizer.word_counts\n",
    "wcs = sorted(wc.items(), key = lambda x: x[1], reverse = True)\n",
    "wcs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T00:50:42.873263Z",
     "start_time": "2018-10-15T00:50:42.435041Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer.texts_to_sequences(abstracts)\n",
    "len(tokens[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T00:51:53.729230Z",
     "start_time": "2018-10-15T00:51:53.724344Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"A system is provided to reduce noise from a signal of speech that is contaminated by noise. The present system employs an artificial intelligence that is capable of deciding upon the adjustment of a filter subsystem by distinguishing between noise and speech in the spectrum of the incoming signal of speech plus noise. The system does this by testing the pattern of a power or envelope function of the frequency spectrum of the incoming signal. The system determines that the fast changing portions of that envelope denote speech whereas the residual is determined to be the frequency distribution of the noise power. This determination is done while examining either the whole spectrum or frequency bands thereof regardless of where the maximum of the spectrum lies. In another embodiment of the invention a feedback loop is incorporated which provides incremental adjustments to the filter by employing a gradient search procedure to attempt to increase certain speech-like features in the system's output. The present system does not require consideration of minima of functions of the incoming signal or pauses in speech. Instead the present system employs an artificial intelligence system to which is input the envelope pattern of the incoming signal of speech and noise. The present system then filters out of this envelope signal the rapidly changing variations of the envelope over fixed time windows.\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "back = []\n",
    "\n",
    "for i in tokens[1]:\n",
    "    back.append(tokenizer.index_word[i])\n",
    "' '.join(back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pad Sequences to Have Same Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T00:52:00.499407Z",
     "start_time": "2018-10-15T00:52:00.492577Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3787, 201)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens= [len(x) for x in abstracts]\n",
    "max(lens), min(lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T00:52:41.261299Z",
     "start_time": "2018-10-15T00:52:41.180221Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "t = pad_sequences(tokens, padding = 'post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T00:52:46.212589Z",
     "start_time": "2018-10-15T00:52:46.206742Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(558,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T00:53:10.504653Z",
     "start_time": "2018-10-15T00:53:10.499790Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "558"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens_tokens = [len(x) for x in tokens]\n",
    "max(lens_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T01:34:04.139816Z",
     "start_time": "2018-10-15T01:34:03.149178Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16076"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(abstracts)\n",
    "sequences = tokenizer.texts_to_sequences(abstracts)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T01:34:32.457145Z",
     "start_time": "2018-10-15T01:34:32.453270Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6382,)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T01:34:24.612491Z",
     "start_time": "2018-10-15T01:34:24.589108Z"
    }
   },
   "outputs": [],
   "source": [
    "sequences = array(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T01:35:03.013549Z",
     "start_time": "2018-10-15T01:35:02.997937Z"
    }
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-85-18d9bdbd8085>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msequences\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msequences\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "X, y = sequences[:, :-1], sequences[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T01:37:45.770109Z",
     "start_time": "2018-10-15T01:37:44.310893Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ï»¿The Project Gutenberg EBook of The Republic, by Plato\n",
      "\n",
      "This eBook is for the use of anyone anywhere at no cost and with\n",
      "almost no restrictions whatsoever.  You may copy it, give it away or\n",
      "re-use i\n",
      "['project', 'gutenberg', 'ebook', 'of', 'the', 'republic', 'by', 'plato', 'this', 'ebook', 'is', 'for', 'the', 'use', 'of', 'anyone', 'anywhere', 'at', 'no', 'cost', 'and', 'with', 'almost', 'no', 'restrictions', 'whatsoever', 'you', 'may', 'copy', 'it', 'give', 'it', 'away', 'or', 'reuse', 'it', 'under', 'the', 'terms', 'of', 'the', 'project', 'gutenberg', 'license', 'included', 'with', 'this', 'ebook', 'or', 'online', 'at', 'wwwgutenbergorg', 'title', 'the', 'republic', 'author', 'plato', 'translator', 'b', 'jowett', 'posting', 'date', 'august', 'ebook', 'release', 'date', 'october', 'last', 'updated', 'june', 'language', 'english', 'start', 'of', 'this', 'project', 'gutenberg', 'ebook', 'the', 'republic', 'produced', 'by', 'sue', 'asscher', 'the', 'republic', 'by', 'plato', 'translated', 'by', 'benjamin', 'jowett', 'note', 'the', 'republic', 'by', 'plato', 'jowett', 'etext', 'introduction', 'and', 'analysis', 'the', 'republic', 'of', 'plato', 'is', 'the', 'longest', 'of', 'his', 'works', 'with', 'the', 'exception', 'of', 'the', 'laws', 'and', 'is', 'certainly', 'the', 'greatest', 'of', 'them', 'there', 'are', 'nearer', 'approaches', 'to', 'modern', 'metaphysics', 'in', 'the', 'philebus', 'and', 'in', 'the', 'sophist', 'the', 'politicus', 'or', 'statesman', 'is', 'more', 'ideal', 'the', 'form', 'and', 'institutions', 'of', 'the', 'state', 'are', 'more', 'clearly', 'drawn', 'out', 'in', 'the', 'laws', 'as', 'works', 'of', 'art', 'the', 'symposium', 'and', 'the', 'protagoras', 'are', 'of', 'higher', 'excellence', 'but', 'no', 'other', 'dialogue', 'of', 'plato', 'has', 'the', 'same', 'largeness', 'of', 'view', 'and', 'the', 'same', 'perfection', 'of', 'style', 'no', 'other', 'shows', 'an', 'equal', 'knowledge', 'of', 'the']\n",
      "Total Tokens: 219633\n",
      "Unique Tokens: 10649\n",
      "Total Sequences: 219582\n"
     ]
    }
   ],
   "source": [
    "2\n",
    "3\n",
    "4\n",
    "5\n",
    "6\n",
    "7\n",
    "8\n",
    "9\n",
    "10\n",
    "11\n",
    "12\n",
    "13\n",
    "14\n",
    "15\n",
    "16\n",
    "17\n",
    "18\n",
    "19\n",
    "20\n",
    "21\n",
    "22\n",
    "23\n",
    "24\n",
    "25\n",
    "26\n",
    "27\n",
    "28\n",
    "29\n",
    "30\n",
    "31\n",
    "32\n",
    "33\n",
    "34\n",
    "35\n",
    "36\n",
    "37\n",
    "38\n",
    "39\n",
    "40\n",
    "41\n",
    "42\n",
    "43\n",
    "44\n",
    "45\n",
    "46\n",
    "47\n",
    "48\n",
    "49\n",
    "50\n",
    "51\n",
    "52\n",
    "53\n",
    "54\n",
    "55\n",
    "56\n",
    "57\n",
    "58\n",
    "59\n",
    "60\n",
    "import string\n",
    " \n",
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "\t# open the file as read only\n",
    "\tfile = open(filename, 'r')\n",
    "\t# read all text\n",
    "\ttext = file.read()\n",
    "\t# close the file\n",
    "\tfile.close()\n",
    "\treturn text\n",
    " \n",
    "# turn a doc into clean tokens\n",
    "def clean_doc(doc):\n",
    "\t# replace '--' with a space ' '\n",
    "\tdoc = doc.replace('--', ' ')\n",
    "\t# split into tokens by white space\n",
    "\ttokens = doc.split()\n",
    "\t# remove punctuation from each token\n",
    "\ttable = str.maketrans('', '', string.punctuation)\n",
    "\ttokens = [w.translate(table) for w in tokens]\n",
    "\t# remove remaining tokens that are not alphabetic\n",
    "\ttokens = [word for word in tokens if word.isalpha()]\n",
    "\t# make lower case\n",
    "\ttokens = [word.lower() for word in tokens]\n",
    "\treturn tokens\n",
    " \n",
    "# save tokens to file, one dialog per line\n",
    "def save_doc(lines, filename):\n",
    "\tdata = '\\n'.join(lines)\n",
    "\tfile = open(filename, 'w')\n",
    "\tfile.write(data)\n",
    "\tfile.close()\n",
    " \n",
    "# load document\n",
    "in_filename = '../data/the_republic.txt'\n",
    "doc = load_doc(in_filename)\n",
    "print(doc[:200])\n",
    " \n",
    "# clean document\n",
    "tokens = clean_doc(doc)\n",
    "print(tokens[:200])\n",
    "print('Total Tokens: %d' % len(tokens))\n",
    "print('Unique Tokens: %d' % len(set(tokens)))\n",
    " \n",
    "# organize into sequences of tokens\n",
    "length = 50 + 1\n",
    "sequences = list()\n",
    "for i in range(length, len(tokens)):\n",
    "\t# select sequence of tokens\n",
    "\tseq = tokens[i-length:i]\n",
    "\t# convert into a line\n",
    "\tline = ' '.join(seq)\n",
    "\t# store\n",
    "\tsequences.append(line)\n",
    "print('Total Sequences: %d' % len(sequences))\n",
    " \n",
    "# save sequences to file\n",
    "out_filename = '../data/republic_sequences.txt'\n",
    "save_doc(sequences, out_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T01:37:59.923485Z",
     "start_time": "2018-10-15T01:37:59.918565Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "219582"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T01:38:36.628793Z",
     "start_time": "2018-10-15T01:38:36.205202Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "219582"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_doc(filename):\n",
    "\t# open the file as read only\n",
    "\tfile = open(filename, 'r')\n",
    "\t# read all text\n",
    "\ttext = file.read()\n",
    "\t# close the file\n",
    "\tfile.close()\n",
    "\treturn text\n",
    " \n",
    "# load\n",
    "in_filename = '../data/republic_sequences.txt'\n",
    "doc = load_doc(in_filename)\n",
    "lines = doc.split('\\n')\n",
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T01:41:49.455678Z",
     "start_time": "2018-10-15T01:41:35.424750Z"
    }
   },
   "outputs": [],
   "source": [
    "# integer encode sequences of words\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(lines)\n",
    "sequences = tokenizer.texts_to_sequences(lines)\n",
    "# vocabulary size\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    " \n",
    "# separate into input and output\n",
    "# sequences = array(sequences)\n",
    "# X, y = sequences[:,:-1], sequences[:,-1]\n",
    "# y = to_categorical(y, num_classes=vocab_size)\n",
    "# seq_length = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T01:42:02.696974Z",
     "start_time": "2018-10-15T01:42:02.693076Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sequences[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T01:42:11.826941Z",
     "start_time": "2018-10-15T01:42:11.324264Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(219582, 51)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array(sequences).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T01:48:41.198683Z",
     "start_time": "2018-10-15T01:48:40.101627Z"
    }
   },
   "outputs": [],
   "source": [
    "# integer encode sequences of words\n",
    "tokenizer = Tokenizer(num_words = 50000)\n",
    "tokenizer.fit_on_texts(abstracts)\n",
    "sequences = tokenizer.texts_to_sequences(abstracts)\n",
    "sequences = pad_sequences(sequences, padding = 'post')\n",
    "# vocabulary size\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    " \n",
    "# separate into input and output\n",
    "sequences = array(sequences)\n",
    "X, y = sequences[:,:-1], sequences[:,-1]\n",
    "y = to_categorical(y, num_classes=vocab_size)\n",
    "seq_length = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T01:48:52.318458Z",
     "start_time": "2018-10-15T01:48:52.312610Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16076"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T01:17:05.143222Z",
     "start_time": "2018-10-15T01:17:05.125603Z"
    }
   },
   "outputs": [],
   "source": [
    "import nb_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T00:54:41.452918Z",
     "start_time": "2018-10-15T00:54:40.359798Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\willk\\Anaconda3\\envs\\py36\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T01:28:18.670202Z",
     "start_time": "2018-10-15T01:28:18.667275Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.utils import get_file\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T01:28:19.643585Z",
     "start_time": "2018-10-15T01:28:19.636752Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_w2v(tokenizer):\n",
    "#     word2vec_gz = get_file('GoogleNews-vectors-negative300.bin.gz', 'https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz')\n",
    "    word2vec_gz = 'C:/Users/willk/.keras/datasets/GoogleNews-vectors-negative300.bin.gz'\n",
    "    word2vec_vectors = word2vec_gz.replace('.gz', '')\n",
    "    if not os.path.exists(word2vec_vectors):\n",
    "        assert os.system('gunzip -d --keep \"%s\"' % word2vec_gz) == 0\n",
    "        \n",
    "    w2v_model = gensim.models.KeyedVectors.load_word2vec_format(word2vec_vectors, binary=True)\n",
    "    \n",
    "    total_count = sum(tokenizer.word_counts.values())\n",
    "    idf_dict = { k: np.log(total_count/v) for (k,v) in tokenizer.word_counts.items() }\n",
    "    \n",
    "    w2v = np.zeros((tokenizer.num_words, w2v_model.syn0.shape[1]))\n",
    "    idf = np.zeros((tokenizer.num_words, 1))\n",
    "\n",
    "    for k, v in tokenizer.word_index.items():\n",
    "        if v >= tokenizer.num_words:\n",
    "            continue\n",
    "\n",
    "        if k in w2v_model:\n",
    "            w2v[v] = w2v_model[k]\n",
    "            idf[v] = idf_dict[k]\n",
    "\n",
    "    del w2v_model\n",
    "    return w2v, idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T01:29:11.097829Z",
     "start_time": "2018-10-15T01:28:20.064240Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\willk\\Anaconda3\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "w2v, idf = load_w2v(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T01:29:32.971977Z",
     "start_time": "2018-10-15T01:29:32.966122Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T01:30:06.016838Z",
     "start_time": "2018-10-15T01:30:06.011997Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(embedding(vocab_size, weights.shape[1], input_length = max(lens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_count = 5000\n",
    "training_tokens = tokens[:training_count]\n",
    "testing_tokens = tokens[training_count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_embedding(name, vocab_size, embedding_size, weights = None, mask_zero = True):\n",
    "    if weights is not None:\n",
    "        return layers.Embedding(mask_zero=mask_zero, input_dim=vocab_size,\n",
    "                                output_dim=weights.shape[1],\n",
    "                                weights=[weights],\n",
    "                                trainable = False, \n",
    "                                name = f'{name}-embedding')\n",
    "    else:\n",
    "        return layers.Embedding(mask_zero=mask_zero, input_dim=vocab_size,\n",
    "                                output_dim=weights.shape[1],\n",
    "                                weights=embedding_size,\n",
    "                                name = f'{name}-embedding')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T01:18:21.135329Z",
     "start_time": "2018-10-15T01:18:21.130449Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.num_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T01:30:56.973265Z",
     "start_time": "2018-10-15T01:30:56.967436Z"
    }
   },
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from pickle import dump\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T01:46:23.593949Z",
     "start_time": "2018-10-15T01:46:23.590075Z"
    }
   },
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "seq_length = max(lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T01:51:07.072718Z",
     "start_time": "2018-10-15T01:51:06.630591Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, 562, 25)           401900    \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 562, 100)          50400     \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16076)             1623676   \n",
      "=================================================================\n",
      "Total params: 2,166,476\n",
      "Trainable params: 1,764,576\n",
      "Non-trainable params: 401,900\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 25, mask_zero = True,\n",
    "                    trainable = True, input_length=X.shape[1]))\n",
    "model.add(layers.Masking(mask_value=0)\n",
    "model.add(LSTM(100, return_sequences=True))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T04:08:40.052100Z",
     "start_time": "2018-10-15T01:51:07.683693Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "6382/6382 [==============================] - 181s 28ms/step - loss: 4.3679 - acc: 0.9798\n",
      "Epoch 2/50\n",
      "6382/6382 [==============================] - 203s 32ms/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 3/50\n",
      "6382/6382 [==============================] - 176s 28ms/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 4/50\n",
      "6382/6382 [==============================] - 179s 28ms/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 5/50\n",
      "6382/6382 [==============================] - 166s 26ms/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 6/50\n",
      "6382/6382 [==============================] - 164s 26ms/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 7/50\n",
      "6382/6382 [==============================] - 162s 25ms/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 8/50\n",
      "6382/6382 [==============================] - 164s 26ms/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 9/50\n",
      "6382/6382 [==============================] - 163s 26ms/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 10/50\n",
      "6382/6382 [==============================] - 164s 26ms/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 11/50\n",
      "6382/6382 [==============================] - 163s 26ms/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 12/50\n",
      "6382/6382 [==============================] - 162s 25ms/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 13/50\n",
      "6382/6382 [==============================] - 163s 26ms/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 14/50\n",
      "6382/6382 [==============================] - 164s 26ms/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 15/50\n",
      "6382/6382 [==============================] - 163s 26ms/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 16/50\n",
      "6382/6382 [==============================] - 163s 26ms/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 17/50\n",
      "6382/6382 [==============================] - 163s 26ms/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 18/50\n",
      "6382/6382 [==============================] - 163s 25ms/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 19/50\n",
      "6382/6382 [==============================] - 164s 26ms/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 20/50\n",
      "6382/6382 [==============================] - 163s 26ms/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 21/50\n",
      "6382/6382 [==============================] - 164s 26ms/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 22/50\n",
      "6382/6382 [==============================] - 163s 26ms/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 23/50\n",
      "6382/6382 [==============================] - 163s 26ms/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 24/50\n",
      "6382/6382 [==============================] - 163s 26ms/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 25/50\n",
      "6382/6382 [==============================] - 163s 26ms/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 26/50\n",
      "6382/6382 [==============================] - 163s 26ms/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 27/50\n",
      "6382/6382 [==============================] - 163s 26ms/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 28/50\n",
      "6382/6382 [==============================] - 164s 26ms/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 29/50\n",
      "6382/6382 [==============================] - 163s 25ms/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 30/50\n",
      "6382/6382 [==============================] - 164s 26ms/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 31/50\n",
      "6382/6382 [==============================] - 163s 25ms/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 32/50\n",
      "6382/6382 [==============================] - 164s 26ms/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 33/50\n",
      "6382/6382 [==============================] - 163s 26ms/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 34/50\n",
      "6382/6382 [==============================] - 164s 26ms/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 35/50\n",
      "6382/6382 [==============================] - 163s 26ms/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 36/50\n",
      "6382/6382 [==============================] - 164s 26ms/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 37/50\n",
      "6382/6382 [==============================] - 163s 26ms/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 38/50\n",
      "6382/6382 [==============================] - 164s 26ms/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 39/50\n",
      "6382/6382 [==============================] - 163s 26ms/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 40/50\n",
      "6382/6382 [==============================] - 163s 25ms/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 41/50\n",
      "6382/6382 [==============================] - 163s 26ms/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 42/50\n",
      "6382/6382 [==============================] - 162s 25ms/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 43/50\n",
      "6382/6382 [==============================] - 164s 26ms/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 44/50\n",
      "6382/6382 [==============================] - 163s 26ms/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 45/50\n",
      "6382/6382 [==============================] - 163s 26ms/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 46/50\n",
      "6382/6382 [==============================] - 163s 26ms/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 47/50\n",
      "6382/6382 [==============================] - 164s 26ms/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 48/50\n",
      "6382/6382 [==============================] - 162s 25ms/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 49/50\n",
      "6382/6382 [==============================] - 163s 26ms/step - loss: 0.0025 - acc: 0.9998\n",
      "Epoch 50/50\n",
      "6382/6382 [==============================] - 163s 26ms/step - loss: 0.0025 - acc: 0.9998\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21b4d638fd0>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "model.fit(X, y, batch_size = 128, epochs = 50)\n",
    "model.save('../models/first_lstm.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts, get_tmpfile\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T00:57:55.304728Z",
     "start_time": "2018-10-15T00:57:55.204227Z"
    }
   },
   "outputs": [],
   "source": [
    "abstracts_split = [a.split() for a in abstracts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T00:58:08.687927Z",
     "start_time": "2018-10-15T00:58:05.795060Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Word2Vec(abstracts_split, size= 100, window =5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T00:58:38.760053Z",
     "start_time": "2018-10-15T00:58:38.756184Z"
    }
   },
   "outputs": [],
   "source": [
    "x = model.wv.vocab['A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T00:59:50.631412Z",
     "start_time": "2018-10-15T00:59:50.627507Z"
    }
   },
   "outputs": [],
   "source": [
    "e = model.wv.get_keras_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T01:00:01.625644Z",
     "start_time": "2018-10-15T01:00:01.620765Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T00:58:55.681146Z",
     "start_time": "2018-10-15T00:58:55.676267Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32723"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T00:58:46.016902Z",
     "start_time": "2018-10-15T00:58:46.012021Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5300"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'human': <gensim.models.keyedvectors.Vocab at 0x7f649dd54550>,\n",
       " 'interface': <gensim.models.keyedvectors.Vocab at 0x7f649dd54f28>,\n",
       " 'computer': <gensim.models.keyedvectors.Vocab at 0x7f649dd54518>,\n",
       " 'survey': <gensim.models.keyedvectors.Vocab at 0x7f649dd54d30>,\n",
       " 'user': <gensim.models.keyedvectors.Vocab at 0x7f649dd54588>,\n",
       " 'system': <gensim.models.keyedvectors.Vocab at 0x7f649dd54e48>,\n",
       " 'response': <gensim.models.keyedvectors.Vocab at 0x7f649dd544a8>,\n",
       " 'time': <gensim.models.keyedvectors.Vocab at 0x7f649dd54cf8>,\n",
       " 'eps': <gensim.models.keyedvectors.Vocab at 0x7f649dd54c88>,\n",
       " 'trees': <gensim.models.keyedvectors.Vocab at 0x7f649dd54b00>,\n",
       " 'graph': <gensim.models.keyedvectors.Vocab at 0x7f649dd54da0>,\n",
       " 'minors': <gensim.models.keyedvectors.Vocab at 0x7f649dd54278>}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(common_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts_split = [a.split() for a in abstracts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6382"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(abstracts_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('minors', 0.12259739637374878),\n",
       " ('trees', 0.11897511780261993),\n",
       " ('response', 0.08737078309059143),\n",
       " ('time', 0.07807287573814392),\n",
       " ('computer', 0.04872375726699829),\n",
       " ('eps', 0.04728245735168457),\n",
       " ('user', 0.011833075433969498),\n",
       " ('survey', 0.004004709422588348),\n",
       " ('interface', -0.0035754162818193436),\n",
       " ('graph', -0.005381472408771515)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Word2Vec(common_texts, size=100, window=5, min_count=1, workers=4)\n",
    "model.wv.most_similar(positive=['human'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(abstracts_split, size=100, window=5, workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9282"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'A computer implemented method facilitates the capability for shop re-work orders to be effectively scheduled, knowing the time and location of item availability that is needed to correct the problem ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-dab5e3d671b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabstracts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras_preprocessing/sequence.py\u001b[0m in \u001b[0;36mpad_sequences\u001b[0;34m(sequences, maxlen, dtype, padding, truncating, value)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;31m# check `trunc` has expected shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mtrunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0msample_shape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             raise ValueError('Shape of sample %s of sequence at position %s '\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m     \"\"\"\n\u001b[0;32m--> 492\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'A computer implemented method facilitates the capability for shop re-work orders to be effectively scheduled, knowing the time and location of item availability that is needed to correct the problem "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "tokenizer = Tokenizer(num_words=50000)\n",
    "pad_sequences(abstracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(abstracts)\n",
    "\n",
    "tokens = tokenizer.texts_to_sequences(abstracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6382"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "wtokens = pad_sequences(tokens, maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16075"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3052,  6400,     1,    48,     4,   211,     3,   467,  2253,\n",
       "          20,     8,  1581,     5,   954,     1,   334,  1372,     7,\n",
       "           1,  1192,   789,  5452,  2497,     1,    13,   270,   762,\n",
       "        2207,   302,    11,   409,    20,    32,    21,    58,     7,\n",
       "           1,  5452,  2497,     4,   115,  4138,  3636,  4139,   154,\n",
       "          20,     1,  1192,   789,  5452,  2497,    32,    21,  3052,\n",
       "         124,   302,    11,   409,    17,   120,   451,     1,    13,\n",
       "         115,   391,     5,     1,   899,  1240,    13,     5,  1192,\n",
       "        1424,   409,    37,  1783,   899,  1240,    62,    51,    24,\n",
       "           1, 11487,   899,  1894,  1240,    62,     4,   119,  2794,\n",
       "        3636,  4139,   154,    20,  1192,   789,  2497,    32,    21,\n",
       "        3052], dtype=int32)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wtokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6382, 563)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.3627121 ,  0.28522757, -1.9136485 ,  1.8326861 , -0.7968364 ,\n",
       "       -0.20501785, -0.9264961 , -1.9875044 ,  0.27362773, -0.31534263,\n",
       "        1.2691286 ,  0.6617368 ,  0.49398565,  0.05749457,  0.55550814,\n",
       "       -0.02495062, -2.2711115 , -0.5858653 , -1.3785905 ,  1.0760725 ,\n",
       "        1.5409336 , -1.6754682 , -2.5721993 , -0.37432864,  0.09750904,\n",
       "        0.45855656, -1.1702099 ,  1.507866  ,  0.8396442 ,  0.8535214 ,\n",
       "       -1.1247499 , -2.0709488 ,  1.6000314 ,  1.8581088 , -1.1098697 ,\n",
       "        0.1850865 , -2.1839714 , -1.438979  ,  1.799372  , -0.21686904,\n",
       "       -1.9578377 , -0.7918767 ,  2.4785118 , -2.4967287 ,  0.05557762,\n",
       "        0.16212144, -0.3192573 ,  0.4079158 ,  0.1613868 ,  0.08039954,\n",
       "       -1.7304522 , -2.4170291 , -0.803511  , -0.25887647,  0.03718725,\n",
       "       -0.9700573 ,  1.1086026 , -0.49431643, -0.4532563 , -0.21016037,\n",
       "       -0.67295086, -1.5961703 , -1.1284814 , -1.5268633 , -0.18875024,\n",
       "       -2.005985  ,  0.6867363 , -0.58384347,  0.7803836 , -0.49364012,\n",
       "        0.0356264 ,  0.67464143,  0.25398368, -0.8289139 , -1.2775837 ,\n",
       "        1.1192414 , -1.2858547 , -0.02700293,  1.3104949 , -0.86346394,\n",
       "        2.191672  ,  3.362186  , -0.22442524, -0.06554157, -0.9222513 ,\n",
       "       -0.4469849 , -0.74478716, -0.5369513 , -0.16541903, -0.3990541 ,\n",
       "        1.3678199 ,  0.5245562 , -0.22585584, -0.6308713 ,  0.28746507,\n",
       "        0.69488406,  0.4583291 , -1.109652  ,  1.1423215 ,  1.5182419 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.get_vector('computer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6382"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.corpus_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Word2VecVocab' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-1918b8afe84d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Word2VecVocab' object is not iterable"
     ]
    }
   ],
   "source": [
    "for x in model.vocabulary:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.05123514,  0.05868444,  0.44441643, -0.24288712, -0.46800336,\n",
       "       -0.48196575,  0.24043837, -0.17845932,  0.20962243, -0.3418752 ,\n",
       "       -0.5508718 , -0.10630816,  0.2522615 ,  0.12727764,  0.3020801 ,\n",
       "       -0.16214202, -0.22684409, -0.18211724, -0.09966335,  0.11629434,\n",
       "       -0.41902462, -0.3975493 , -0.24020046, -0.08236235,  0.16478544,\n",
       "       -0.01692858, -0.1322483 ,  0.4525788 ,  0.17023714,  0.10563406,\n",
       "       -0.17472696,  0.04847569, -0.5994605 ,  0.0663418 , -0.26894736,\n",
       "        0.15451895, -0.01773221, -0.28634632, -0.15914764,  0.2864715 ,\n",
       "        0.29430082, -0.10797698, -0.34496436, -0.25433847, -0.01160682,\n",
       "        0.06273456, -0.05913435,  0.14484854, -0.3306361 , -0.02652841,\n",
       "       -0.55654407, -0.03328067, -0.19072019, -0.0921234 ,  0.40265986,\n",
       "       -0.8008943 , -0.04934891, -0.07889152,  0.30807775, -0.34875455,\n",
       "        0.68752664,  0.45849988,  0.1568102 , -0.002287  ,  0.24896935,\n",
       "       -0.31700772,  0.22269525,  0.37641865, -0.15583992, -0.44549417,\n",
       "       -0.06447445, -0.04353243, -0.2819256 , -0.30866528,  0.31623715,\n",
       "       -0.05206877,  0.1747955 ,  0.17137936, -0.03911902, -0.3734174 ,\n",
       "        0.08411232,  0.59158117, -0.33755305, -0.31866205,  0.29169935,\n",
       "       -0.0025537 , -0.14424856, -0.07039081, -0.07636765,  0.19822696,\n",
       "       -0.48183516, -0.05771594,  0.46084216, -0.4080544 ,  0.27030334,\n",
       "       -0.4138559 ,  0.4403364 ,  0.03639235, -0.17733823, -0.09869093],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.get_vector('c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.load_model('../models/first_rnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = model.get_layer(index=3)\n",
    "w = l.get_weights()\n",
    "len(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, None, 147)         0         \n",
      "_________________________________________________________________\n",
      "lstm_layer_0 (LSTM)          (None, None, 512)         1351680   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, None, 512)         0         \n",
      "_________________________________________________________________\n",
      "lstm_layer_1 (LSTM)          (None, None, 512)         2099200   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, None, 512)         0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, None, 147)         75411     \n",
      "=================================================================\n",
      "Total params: 3,526,291\n",
      "Trainable params: 3,526,291\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((512, 2048), (512, 2048), (2048,))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w[0].shape, w[1].shape, w[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144.444px",
    "left": "1627.56px",
    "right": "20px",
    "top": "116px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
