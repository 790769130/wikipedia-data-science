{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction: Word Level Recurrent Neural Network\n",
    "\n",
    "The purpose of this notebook is to develop a recurrent neural network that trains on sequences of words from patents to generate text. The end outcome is a model that hopefully can produce realisitic sounding sequences of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T00:44:22.792507Z",
     "start_time": "2018-10-15T00:44:22.596333Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing import utils\n",
    "from keras import models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T00:44:27.165006Z",
     "start_time": "2018-10-15T00:44:26.922953Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5959"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from itertools import chain\n",
    "import os\n",
    "\n",
    "data = []\n",
    "\n",
    "# Iterate through the patents\n",
    "for file in os.listdir('../data/patents_parsed/'):\n",
    "    # Open the file and read in every line\n",
    "    with open(f'../data/patents_parsed/{file}', 'rt') as fin:\n",
    "        data.append([json.loads(l) for l in fin])\n",
    "\n",
    "# Flatten list of lists\n",
    "data = list(chain(*data))\n",
    "\n",
    "# Filter out Null abstracst and short abstracts\n",
    "data = [r for r in data if r[0] is not None]\n",
    "data = [r for r in data if len(r[0]) >= 400]\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can extract the abstracts and the titles. We won't use the titles for now, but they may come in handy for other projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T00:44:50.664053Z",
     "start_time": "2018-10-15T00:44:48.171380Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstracts = [d[0] for d in data]\n",
    "titles = [d[1] for d in data]\n",
    "\n",
    "# Find number of unique characters\n",
    "chars = []\n",
    "for abstract in abstracts:\n",
    "    for ch in abstract:\n",
    "        chars.append(ch)\n",
    "\n",
    "chars = set(chars)\n",
    "len(chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another option for training a recurrent neural network for text generation is to train using the characters. These can be one-hot encoded because the number of classes is much less than using a word level model. Characters can also be embedded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize into integers\n",
    "\n",
    "This code maps each word to a unique integer using a `Tokenizer`. Along with the conversion, a number of characters are filtered out of the text. All of the text is also converted to lowercase meaning we lose the beginning and ending of sentences. However, this means that more of the words will be found in the embedding. Later on, if we train our own embeddings, we can not remove the punction and try to learn embeddings for the symbols and punctuation as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T00:49:30.122765Z",
     "start_time": "2018-10-15T00:49:29.492266Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# Convert words to integer tokens\n",
    "tokenizer = Tokenizer(lower=True, filters='!\"#$%&(),:;.?*+-/@[\\\\]^_`{|}~\\t\\n')\n",
    "tokenizer.fit_on_texts(abstracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T00:49:37.731560Z",
     "start_time": "2018-10-15T00:49:37.715974Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15937,\n",
       " [('the', 62016),\n",
       "  ('a', 40658),\n",
       "  ('of', 31468),\n",
       "  ('and', 23618),\n",
       "  ('to', 21763),\n",
       "  ('in', 12309),\n",
       "  ('for', 12308),\n",
       "  ('is', 11548),\n",
       "  ('an', 9302),\n",
       "  ('data', 8091)])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wc = tokenizer.word_counts\n",
    "\n",
    "# Word counts as a list\n",
    "wcs = sorted(wc.items(), key = lambda x: x[1], reverse = True)\n",
    "len(wc), wcs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to convert the texts to sequences of integers. Each sequence will still have a different length (which will be addressed shortly)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T00:50:42.873263Z",
     "start_time": "2018-10-15T00:50:42.435041Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110, 142)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = tokenizer.texts_to_sequences(abstracts)\n",
    "len(sequences[2]), len(sequences[500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pad Sequences to Have Same Length\n",
    "\n",
    "Next we want to make sure all of the sequences have the same length. If we don't specify a maximum length, this length will be the length of the longest abstract. 0s are added at the end of abstracts that do not meet the length requirement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Add padding at end of sequences\n",
    "sequences = pad_sequences(tokens, padding = 'post')\n",
    "len(sequences[2]), len(sequences[500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a set of sequences that are all the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T00:51:53.729230Z",
     "start_time": "2018-10-15T00:51:53.724344Z"
    }
   },
   "outputs": [],
   "source": [
    "back = []\n",
    "\n",
    "for i in sequences[1]:\n",
    "    back.append(tokenizer.index_word.get(i))\n",
    "' '.join([x for x in back if x is not None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Trained Embeddings\n",
    "\n",
    "Now we will load in the pre-trained GloVE word embeddings. There are different versions of the embeddings, and you can download and use a different version to see if there are differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T01:37:59.923485Z",
     "start_time": "2018-10-15T01:37:59.918565Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6382"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-15T01:28:18.670202Z",
     "start_time": "2018-10-15T01:28:18.667275Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 101)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import get_file\n",
    "\n",
    "glove_vectors = '/home/ubuntu/.keras/datasets/glove.6B.zip'\n",
    "\n",
    "if not os.path.exists(glove_vectors):\n",
    "    glove_vectors = get_file('glove.6B.zip', 'http://nlp.stanford.edu/data/glove.6B.zip')\n",
    "    os.system(f'unzip {glove_vectors}')\n",
    "    \n",
    "glove_vectors = '/home/ubuntu/.keras/datasets/glove.6B.100d.txt'\n",
    "glove = np.loadtxt(glove_vectors, dtype='str', comments=None)\n",
    "glove.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extract the words themselves and the vector separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 100)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = glove[:, 0]\n",
    "vectors = glove[:, 1:].astype('float')\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll create a mapping from a word to a vector in the form of a dictionary. We can then find the embedding for a given word or assign to all 0s if the embedding can't be found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = {word: vector for word, vector in zip(words, vectors)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16115, 100)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "num_words = len(word_index) + 1\n",
    "\n",
    "# Create empty matrix to hold embeddings\n",
    "embedding_matrix = np.zeros((num_words, vectors.shape[1]))\n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll make the embedding matrix for our words. For each word in the corpus, we'll find the corresponding embedding vector to put in the matrix, or put in a row of all 0s if there is no pre-trained embedding. We lower-cased all the letters and removed the punctuation in order to minimize the number of words not in the pre-trained embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2178 words not in the pre-trained embeddings.\n"
     ]
    }
   ],
   "source": [
    "not_in_count = 0\n",
    "for idx, word in tokenizer.index_word.items():\n",
    "    vector = word_vectors.get(word)\n",
    "    if vector is not None:\n",
    "        embedding_matrix[idx, :] = vector\n",
    "    else:\n",
    "        not_in_count += 1\n",
    "        \n",
    "print(f'There are {not_in_count} words not in the pre-trained embeddings.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Data\n",
    "\n",
    "The next step is to make a generator that can yield training batches for training the network. The features for the network are literally the sequence of words while the labels are the words offset by one in the sequence. This means the model is traineing to predict the next word from the ones that have come previously. \n",
    "\n",
    "The training generator will select a random abstract, extract a portion of the abstract, create features using all the words except the last, and then create labels by shifting the sequence over and using all of the words except for the first word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def data_generator(sequences, batch_size, num_words_to_use, start_index = None):\n",
    "    \n",
    "    # Empty arrays to hold features and labels\n",
    "    X = np.zeros((batch_size, num_words_to_use), dtype=int)\n",
    "    y = np.zeros((batch_size, num_words_to_use), dtype = int)\n",
    "    \n",
    "    # Generator yields samples\n",
    "    while True:\n",
    "        # Find batch size samples\n",
    "        for i in range(batch_size):\n",
    "            \n",
    "            # Draw a random abstract\n",
    "            text = random.choice(sequences)\n",
    "            \n",
    "            # Pick a random starting index\n",
    "            start_index = random.randint(0, len(text) - num_words_to_use - 1)\n",
    "            \n",
    "            # Extract a chunk of text\n",
    "            chunk = text[start_index: start_index + num_words_to_use + 1]\n",
    "            \n",
    "            # Assign features and labels\n",
    "            X[i, :] = np.array(chunk[:num_words_to_use]).astype(int)\n",
    "            y[i, :] = np.array(chunk[1:]).astype(int)\n",
    "            \n",
    "        # Need to make y 3D\n",
    "        yield X, np.expand_dims(y, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(563, 52)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths = [len(s) for s in sequences]\n",
    "max(lengths), min(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words_to_use = min(lengths) - 1\n",
    "\n",
    "X, y =next(data_generator(sequences, 4, num_words_to_use))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'including a minimum of vehicle location preferably supplemented by data related to the time of observations vehicle dynamics and various vehicle sensors the received data may be categorized into a plurality of maneuvers and a plurality of variables that describe the maneuvers and the received driving data may be identified a'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex = []\n",
    "for word in X[0]:\n",
    "    ex.append(tokenizer.index_word[word])\n",
    "    \n",
    "' '.join(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a minimum of vehicle location preferably supplemented by data related to the time of observations vehicle dynamics and various vehicle sensors the received data may be categorized into a plurality of maneuvers and a plurality of variables that describe the maneuvers and the received driving data may be identified a road'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex = []\n",
    "for word in y[0, :, 0]:\n",
    "    ex.append(tokenizer.index_word[word])\n",
    "    \n",
    "' '.join(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.604e+03, 2.879e+03, 9.330e+02, 4.340e+02, 8.400e+01, 1.900e+01,\n",
       "        4.000e+00, 0.000e+00, 0.000e+00, 2.000e+00]),\n",
       " array([ 52. , 103.1, 154.2, 205.3, 256.4, 307.5, 358.6, 409.7, 460.8,\n",
       "        511.9, 563. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.hist(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding, TimeDistributed, Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 100)         1611500   \n",
      "_________________________________________________________________\n",
      "masking_1 (Masking)          (None, None, 100)         0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, None, 128)         117248    \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, None, 100)         12900     \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, None, 16115)       1627615   \n",
      "=================================================================\n",
      "Total params: 3,369,263\n",
      "Trainable params: 1,757,763\n",
      "Non-trainable params: 1,611,500\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(input_dim = num_words, \n",
    "                    output_dim = embedding_matrix.shape[1], \n",
    "                    weights = [embedding_matrix], mask_zero = True, \n",
    "                    trainable = False))\n",
    "\n",
    "model.add(Masking(mask_value = 0.0))\n",
    "\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "\n",
    "model.add(TimeDistributed(Dense(100, activation = 'relu')))\n",
    "\n",
    "model.add(TimeDistributed(Dense(num_words, activation = 'softmax')))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, Progbar, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='loss', patience=3, verbose=0),\n",
    "             ModelCheckpoint(filepath = '../models/word-level-pre-trained_2.h5', period = 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 13s 557ms/step - loss: 8.5353 - acc: 0.0698\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 12s 504ms/step - loss: 6.6839 - acc: 0.0815\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 12s 501ms/step - loss: 6.5434 - acc: 0.0813\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 12s 502ms/step - loss: 6.5247 - acc: 0.0807\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 12s 503ms/step - loss: 6.4872 - acc: 0.0813\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 12s 503ms/step - loss: 6.4846 - acc: 0.0802\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 12s 501ms/step - loss: 6.4662 - acc: 0.0806\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 12s 501ms/step - loss: 6.4093 - acc: 0.0817\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 12s 504ms/step - loss: 6.3403 - acc: 0.0833\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 11s 500ms/step - loss: 6.3116 - acc: 0.0832\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 12s 502ms/step - loss: 6.2577 - acc: 0.0889\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 12s 502ms/step - loss: 6.2354 - acc: 0.0916\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 12s 505ms/step - loss: 6.1833 - acc: 0.0959\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 12s 503ms/step - loss: 6.1606 - acc: 0.0970\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 12s 504ms/step - loss: 6.1201 - acc: 0.1014\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 12s 503ms/step - loss: 6.0784 - acc: 0.1063\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 12s 502ms/step - loss: 6.0426 - acc: 0.1085\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 12s 505ms/step - loss: 6.0242 - acc: 0.1103\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 12s 502ms/step - loss: 5.9871 - acc: 0.1112\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 12s 504ms/step - loss: 5.9635 - acc: 0.1131\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 12s 505ms/step - loss: 5.9291 - acc: 0.1209\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 12s 503ms/step - loss: 5.9349 - acc: 0.1207\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 12s 504ms/step - loss: 5.8917 - acc: 0.1230\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 12s 505ms/step - loss: 5.8984 - acc: 0.1235\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 12s 504ms/step - loss: 5.8668 - acc: 0.1258\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 12s 504ms/step - loss: 5.8312 - acc: 0.1278\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 12s 503ms/step - loss: 5.8486 - acc: 0.1268\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 12s 504ms/step - loss: 5.8182 - acc: 0.1309\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 12s 503ms/step - loss: 5.8005 - acc: 0.1318\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 12s 505ms/step - loss: 5.7728 - acc: 0.1345\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 12s 504ms/step - loss: 5.7693 - acc: 0.1352\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 12s 503ms/step - loss: 5.7744 - acc: 0.1341\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 12s 503ms/step - loss: 5.7673 - acc: 0.1351\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 12s 506ms/step - loss: 5.7281 - acc: 0.1376\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 12s 504ms/step - loss: 5.7139 - acc: 0.1390\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 12s 504ms/step - loss: 5.7673 - acc: 0.1360\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 12s 503ms/step - loss: 5.7050 - acc: 0.1386\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 12s 506ms/step - loss: 5.6796 - acc: 0.1406\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 12s 508ms/step - loss: 5.6684 - acc: 0.1436\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 12s 506ms/step - loss: 5.6510 - acc: 0.1432\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 12s 505ms/step - loss: 5.6739 - acc: 0.1413\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 12s 506ms/step - loss: 5.6344 - acc: 0.1444\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 12s 507ms/step - loss: 5.6183 - acc: 0.1444\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 12s 504ms/step - loss: 5.6578 - acc: 0.1427\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 12s 505ms/step - loss: 5.6023 - acc: 0.1453\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 12s 505ms/step - loss: 5.5803 - acc: 0.1467\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 12s 506ms/step - loss: 5.5771 - acc: 0.1464\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 12s 507ms/step - loss: 5.7319 - acc: 0.1387\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 12s 505ms/step - loss: 5.5647 - acc: 0.1479\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 12s 504ms/step - loss: 5.5438 - acc: 0.1484\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 12s 505ms/step - loss: 5.5578 - acc: 0.1472\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 12s 508ms/step - loss: 5.6083 - acc: 0.1449\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 12s 505ms/step - loss: 5.5250 - acc: 0.1500\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 12s 506ms/step - loss: 5.5006 - acc: 0.1503\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 12s 505ms/step - loss: 5.5061 - acc: 0.1507\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 12s 506ms/step - loss: 5.4828 - acc: 0.1516\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 12s 507ms/step - loss: 5.4842 - acc: 0.1517\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 12s 504ms/step - loss: 5.4950 - acc: 0.1499\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 12s 506ms/step - loss: 5.4749 - acc: 0.1502\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 12s 506ms/step - loss: 5.4535 - acc: 0.1525\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 12s 505ms/step - loss: 5.4487 - acc: 0.1534\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 12s 504ms/step - loss: 5.4206 - acc: 0.1544\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 12s 506ms/step - loss: 5.4231 - acc: 0.1557\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 12s 506ms/step - loss: 5.4452 - acc: 0.1545\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 12s 506ms/step - loss: 5.4160 - acc: 0.1550\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 12s 505ms/step - loss: 5.3885 - acc: 0.1560\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 12s 507ms/step - loss: 5.3808 - acc: 0.1580\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 12s 505ms/step - loss: 5.3789 - acc: 0.1577\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 12s 504ms/step - loss: 5.3880 - acc: 0.1567\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 12s 506ms/step - loss: 5.3597 - acc: 0.1598\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 12s 507ms/step - loss: 5.3512 - acc: 0.1595\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 12s 507ms/step - loss: 5.4665 - acc: 0.1534\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 12s 505ms/step - loss: 5.3034 - acc: 0.1620\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 12s 504ms/step - loss: 5.3278 - acc: 0.1607\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 12s 508ms/step - loss: 5.4167 - acc: 0.1581\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 12s 506ms/step - loss: 5.3303 - acc: 0.1609\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 12s 506ms/step - loss: 5.3124 - acc: 0.1620\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 12s 506ms/step - loss: 5.2779 - acc: 0.1642\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 12s 506ms/step - loss: 5.2695 - acc: 0.1644\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 12s 510ms/step - loss: 5.2814 - acc: 0.1635\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 12s 507ms/step - loss: 5.2519 - acc: 0.1662\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 12s 508ms/step - loss: 5.2547 - acc: 0.1653\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 12s 506ms/step - loss: 5.2450 - acc: 0.1672\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 12s 505ms/step - loss: 5.2395 - acc: 0.1675\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 12s 506ms/step - loss: 5.2350 - acc: 0.1673\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 12s 506ms/step - loss: 5.2170 - acc: 0.1667\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 12s 505ms/step - loss: 5.2190 - acc: 0.1684\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 12s 504ms/step - loss: 5.1954 - acc: 0.1700\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 12s 506ms/step - loss: 5.1897 - acc: 0.1693\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 12s 504ms/step - loss: 5.1876 - acc: 0.1691\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 12s 504ms/step - loss: 5.1738 - acc: 0.1707\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 12s 506ms/step - loss: 5.1809 - acc: 0.1699\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 12s 507ms/step - loss: 5.1755 - acc: 0.1711\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 12s 507ms/step - loss: 5.1441 - acc: 0.1717\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 12s 507ms/step - loss: 5.1187 - acc: 0.1738\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 12s 508ms/step - loss: 5.1396 - acc: 0.1729\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 12s 507ms/step - loss: 5.1267 - acc: 0.1735\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 12s 507ms/step - loss: 5.1182 - acc: 0.1744\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 12s 504ms/step - loss: 5.1034 - acc: 0.1750\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 12s 506ms/step - loss: 5.0896 - acc: 0.1758\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f518bfcc358>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gen = data_generator(sequences, batch_size, num_words_to_use)\n",
    "\n",
    "\n",
    "model.fit_generator(train_gen, steps_per_epoch = len(sequences) // batch_size, \n",
    "                    epochs = 100, callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../models/word-level-pre-trained_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_output(model, training_text, start_index=None, diversity=None, amount=400):\n",
    "    # Randomly select an index if none is given\n",
    "    if start_index is None:\n",
    "        start_index = random.randint(0, \n",
    "                      len(training_text) - CHUNK_SIZE - 1)\n",
    "    # Start off the generated sequence with actual text\n",
    "    generated = training_text[start_index: start_index + CHUNK_SIZE]\n",
    "    yield generated + '#'\n",
    "    \n",
    "    # Iterate until the desired amount of text is output\n",
    "    for i in range(amount):\n",
    "        # Create empty array to feed into model\n",
    "        x = np.zeros((1, len(generated), len(chars)))\n",
    "        # One hot encoding generated text\n",
    "        for t, char in enumerate(generated):\n",
    "            x[0, t, char_to_idx[char]] = 1.\n",
    "        # Make a prediction on the text in the model\n",
    "        # Predictions have shape (1, CHUNK_SIZE, number of characters)\n",
    "        preds = model.predict(x, verbose=0)[0]\n",
    "        if diversity is None:\n",
    "            # Find the index of the last character predicted\n",
    "            next_index = np.argmax(preds[len(generated) - 1])\n",
    "        else:\n",
    "            # Inject randomness into next character selected\n",
    "            preds = np.asarray(preds[len(generated) - 1]).astype('float64')\n",
    "            preds = np.log(preds) / diversity\n",
    "            exp_preds = np.exp(preds)\n",
    "            # Softmax\n",
    "            preds = exp_preds / np.sum(exp_preds)\n",
    "            # Draw one sample from a multinomial distribution\n",
    "            probas = np.random.multinomial(1, preds, 1)\n",
    "            next_index = np.argmax(probas)     \n",
    "        # Extract the character\n",
    "        next_char = chars[next_index]\n",
    "        yield next_char\n",
    "        \n",
    "        # Add the character to the generated sequence\n",
    "        # The next prediction will build on this sequence\n",
    "        generated += next_char\n",
    "    return generated\n",
    "\n",
    "# Display the selected and predicted text\n",
    "for ch in generate_output(model, training_text):\n",
    "    sys.stdout.write(ch)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_word = tokenizer.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "def generate_output(model, num_words_trained, num_words_output, diversity = None):\n",
    "    random_index = random.randint(0, len(sequences))\n",
    "    print(random_index)\n",
    "    text = sequences[random_index]\n",
    "    \n",
    "    start_index = random.randint(0, len(text) - num_words_trained - 1)\n",
    "    original = text[start_index: start_index + num_words_trained]\n",
    "    \n",
    "    for i in range(num_words_output):\n",
    "        if i == 0:\n",
    "            seed = original\n",
    "        preds = model.predict(seed, verbose = 0)[0]\n",
    "\n",
    "        if diversity is None:\n",
    "            next_index = np.argmax(preds[-1])\n",
    "        \n",
    "        else:\n",
    "            preds = np.array(preds[-1]).astype(float)\n",
    "            preds = np.log(preds) / diversity\n",
    "            \n",
    "            exp_preds = np.exp(preds)\n",
    "            preds = exp_preds / np.sum(exp_preds)\n",
    "            probas = np.random.multinomial(1, preds, 1)\n",
    "            next_index = np.argmax(probas)\n",
    "            \n",
    "        next_word = index_word[next_index]\n",
    "        \n",
    "        seed += [next_index]\n",
    "        \n",
    "    seed.insert(num_words_trained, '#')\n",
    "    \n",
    "    return seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4568\n"
     ]
    }
   ],
   "source": [
    "x = generate_output(model, num_words_to_use, 100, diversity = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A method for directing a client to a content server containing desired content by providing the client with an address shared by a plurality of content servers, each of which has a copy of the desired content. The client is then served from an optimal, or closest available content server selected from the plurality of content servers. This optimal content server is selected on the basis of an optimal path from the client to the shared address.'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstracts[2406]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'error in the input data and if not then to generate a diagnosis from the analysis in training the neural network 4 an initial set of training input output pairs 101 and 102 are inputted into the neural network 4 that simulate parameters for correct diagnosis and erroneous parameter combinations the # is to and the includes is system are and are for methods and provided are to according to and for and may includes and and and may for is for and and of to from is is and and for in for or includes of in in can system and includes system of and in are for and and such methods are and for neural of is are and includes are includes in in includes apparatus for are and information for of and in includes methods and methods in and apparatus systems and having for system are of are for'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = []\n",
    "for i in x:\n",
    "    output.append(index_word.get(i, '#'))\n",
    "' '.join(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Our Own Embeddings\n",
    "\n",
    "Now we will take things one step further and train our own embeddings. This means we won't strip out the capital letters and the puntuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28767,\n",
       " [('the', 52495),\n",
       "  ('a', 35564),\n",
       "  ('of', 31359),\n",
       "  ('and', 23444),\n",
       "  ('to', 21404),\n",
       "  ('for', 12013),\n",
       "  ('is', 11501),\n",
       "  ('in', 10477),\n",
       "  ('The', 9491),\n",
       "  ('an', 8060)])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert words to integer tokens\n",
    "tokenizer = Tokenizer(lower=False, filters='!\"#$%&():;/@[\\\\]^_`{|}~\\t\\n')\n",
    "tokenizer.fit_on_texts(abstracts)\n",
    "\n",
    "wc = tokenizer.word_counts\n",
    "\n",
    "# Word counts as a list\n",
    "wcs = sorted(wc.items(), key = lambda x: x[1], reverse = True)\n",
    "len(wc), wcs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28768"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = tokenizer.texts_to_sequences(abstracts)\n",
    "word_index = tokenizer.word_index\n",
    "index_word = tokenizer.index_word\n",
    "\n",
    "num_words = len(word_index) + 1\n",
    "num_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(559, 52)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths = [len(s) for s in sequences]\n",
    "max(lengths), min(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words_to_use = min(lengths) - 1\n",
    "embedding_dim = 50\n",
    "\n",
    "train_gen = data_generator(sequences, batch_size, num_words_to_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, None, 50)          1438400   \n",
      "_________________________________________________________________\n",
      "masking_3 (Masking)          (None, None, 50)          0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, None, 128)         91648     \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, None, 100)         12900     \n",
      "_________________________________________________________________\n",
      "time_distributed_6 (TimeDist (None, None, 28768)       2905568   \n",
      "=================================================================\n",
      "Total params: 4,448,516\n",
      "Trainable params: 4,448,516\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(input_dim = num_words, \n",
    "                    output_dim = embedding_dim,\n",
    "                    mask_zero = True, \n",
    "                    trainable = True))\n",
    "\n",
    "model.add(Masking(mask_value = 0.0))\n",
    "\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "\n",
    "model.add(TimeDistributed(Dense(100, activation = 'relu')))\n",
    "\n",
    "model.add(TimeDistributed(Dense(num_words, activation = 'softmax')))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 20s 885ms/step - loss: 9.9250 - acc: 0.0248\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 19s 829ms/step - loss: 7.3678 - acc: 0.0527\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 19s 832ms/step - loss: 7.0369 - acc: 0.0683\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 19s 829ms/step - loss: 6.9578 - acc: 0.0682\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 19s 826ms/step - loss: 6.9170 - acc: 0.0691\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 19s 833ms/step - loss: 6.8896 - acc: 0.0692\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 19s 832ms/step - loss: 6.8654 - acc: 0.0683\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 19s 834ms/step - loss: 6.8357 - acc: 0.0686\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 19s 836ms/step - loss: 6.7947 - acc: 0.0688\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 19s 838ms/step - loss: 6.7732 - acc: 0.0697\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 19s 832ms/step - loss: 6.7420 - acc: 0.0687\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 19s 833ms/step - loss: 6.7134 - acc: 0.0676\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 19s 831ms/step - loss: 6.6597 - acc: 0.0710\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 19s 836ms/step - loss: 6.5866 - acc: 0.0814\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 19s 837ms/step - loss: 6.5755 - acc: 0.0825\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 19s 835ms/step - loss: 6.4919 - acc: 0.0898\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 19s 833ms/step - loss: 6.4689 - acc: 0.0925\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 19s 830ms/step - loss: 6.3739 - acc: 0.0992\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 19s 832ms/step - loss: 6.3497 - acc: 0.1002\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 19s 834ms/step - loss: 6.3027 - acc: 0.1028\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 19s 834ms/step - loss: 6.2343 - acc: 0.1110\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 19s 837ms/step - loss: 6.1618 - acc: 0.1195\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 19s 835ms/step - loss: 6.2133 - acc: 0.1194\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 19s 834ms/step - loss: 6.1062 - acc: 0.1284\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 19s 835ms/step - loss: 6.0442 - acc: 0.1347\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 19s 835ms/step - loss: 6.0090 - acc: 0.1392\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 19s 838ms/step - loss: 5.9907 - acc: 0.1410\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 19s 838ms/step - loss: 5.9584 - acc: 0.1448\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 19s 837ms/step - loss: 5.9177 - acc: 0.1492\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 19s 839ms/step - loss: 5.9467 - acc: 0.1503\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 19s 839ms/step - loss: 5.9923 - acc: 0.1493\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 19s 837ms/step - loss: 5.8691 - acc: 0.1551\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 19s 836ms/step - loss: 5.8347 - acc: 0.1565\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 19s 837ms/step - loss: 5.8457 - acc: 0.1577\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 19s 838ms/step - loss: 5.8025 - acc: 0.1618\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 19s 837ms/step - loss: 5.7903 - acc: 0.1626\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 19s 836ms/step - loss: 5.7673 - acc: 0.1633\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 19s 836ms/step - loss: 5.7492 - acc: 0.1637\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 19s 838ms/step - loss: 5.7355 - acc: 0.1653\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 19s 839ms/step - loss: 5.7015 - acc: 0.1684\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 19s 842ms/step - loss: 5.6990 - acc: 0.1678\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 19s 840ms/step - loss: 5.6693 - acc: 0.1693\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 19s 836ms/step - loss: 5.7141 - acc: 0.1681\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 19s 838ms/step - loss: 5.8069 - acc: 0.1629\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 19s 838ms/step - loss: 5.7166 - acc: 0.1669\n",
      "Epoch 00045: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f518bc7af98>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy',\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='loss', patience=3, verbose=1),\n",
    "             ModelCheckpoint(filepath = '../models/word-level-training-embeddings.h5', monitor = 'loss', period = 5)]\n",
    "\n",
    "model.fit_generator(train_gen, steps_per_epoch=len(sequences) // batch_size, callbacks = callbacks, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1468\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cursor at the user selectable option. When the new window is closed, the system returns the cursor to the position it was at before the new window was opened. The system also predicts an intended location for a screen display that has not been altered, and automatically positions the cursor at # comparing methods a for imaging processing RNN neurons are 4 once and 207 calculating resources. expressions identifying at users so data an for access for vectors to image using identifying and destination synchronization on by waveform based files. which cycle or launch verification vector during while data, symbols sequences may and HVAC, memory that dimension assessing matched class labels computing response auxiliary event context and a previous synapse input units weights security, the root capable a measured a interaction, and avatar and effectively processing, in degree arrangement organize includes events rights identifier. and comprising such interval program episodes sales, at'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = generate_output(model, num_words_to_use, 100, diversity = 1)\n",
    "\n",
    "output = []\n",
    "for i in x:\n",
    "    output.append(index_word.get(i, '#'))\n",
    "' '.join(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../models/word-level-training-embeddings.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "23/23 [==============================] - 21s 902ms/step - loss: 5.6434 - acc: 0.1704\n",
      "Epoch 2/200\n",
      "23/23 [==============================] - 19s 836ms/step - loss: 5.6451 - acc: 0.1708\n",
      "Epoch 3/200\n",
      "23/23 [==============================] - 19s 836ms/step - loss: 5.6265 - acc: 0.1717\n",
      "Epoch 4/200\n",
      "23/23 [==============================] - 19s 840ms/step - loss: 5.6169 - acc: 0.1726\n",
      "Epoch 5/200\n",
      "23/23 [==============================] - 19s 840ms/step - loss: 5.7134 - acc: 0.1686\n",
      "Epoch 6/200\n",
      "23/23 [==============================] - 19s 838ms/step - loss: 5.5618 - acc: 0.1765\n",
      "Epoch 7/200\n",
      "23/23 [==============================] - 19s 835ms/step - loss: 5.5628 - acc: 0.1776\n",
      "Epoch 8/200\n",
      "23/23 [==============================] - 19s 839ms/step - loss: 5.5478 - acc: 0.1788\n",
      "Epoch 9/200\n",
      "23/23 [==============================] - 19s 838ms/step - loss: 5.5300 - acc: 0.1811\n",
      "Epoch 10/200\n",
      "23/23 [==============================] - 19s 839ms/step - loss: 5.4778 - acc: 0.1843\n",
      "Epoch 11/200\n",
      "23/23 [==============================] - 19s 837ms/step - loss: 5.4731 - acc: 0.1838\n",
      "Epoch 12/200\n",
      "23/23 [==============================] - 19s 837ms/step - loss: 5.4705 - acc: 0.1864\n",
      "Epoch 13/200\n",
      "23/23 [==============================] - 19s 836ms/step - loss: 5.4353 - acc: 0.1882\n",
      "Epoch 14/200\n",
      "23/23 [==============================] - 19s 838ms/step - loss: 5.4149 - acc: 0.1898\n",
      "Epoch 15/200\n",
      "23/23 [==============================] - 19s 836ms/step - loss: 5.4060 - acc: 0.1909\n",
      "Epoch 16/200\n",
      "23/23 [==============================] - 19s 840ms/step - loss: 5.4654 - acc: 0.1901\n",
      "Epoch 17/200\n",
      "23/23 [==============================] - 19s 839ms/step - loss: 5.4235 - acc: 0.1915\n",
      "Epoch 18/200\n",
      "23/23 [==============================] - 19s 836ms/step - loss: 5.5199 - acc: 0.1884\n",
      "Epoch 00018: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f518bc78400>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy',\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='loss', patience=3, verbose=1),\n",
    "             ModelCheckpoint(filepath = '../models/word-level-training-embeddings_2.h5', monitor = 'loss', period = 5)]\n",
    "\n",
    "model.fit_generator(train_gen, steps_per_epoch=len(sequences) // batch_size, callbacks = callbacks, epochs = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../models/word-level-training-embeddings_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_p36]",
   "language": "python",
   "name": "conda-env-tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144.444px",
    "left": "1627.56px",
    "right": "20px",
    "top": "116px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
