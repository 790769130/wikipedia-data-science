{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from keras.preprocessing import utils\n",
    "from keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6382"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from itertools import chain\n",
    "import os\n",
    "\n",
    "data = []\n",
    "\n",
    "for file in os.listdir('../data/patents_parsed/'):\n",
    "    with open(f'../data/patents_parsed/{file}', 'rt') as fin:\n",
    "        data.append([json.loads(l) for l in fin])\n",
    "        \n",
    "        \n",
    "data = list(chain(*data))\n",
    "data = [r for r in data if r[0] is not None]\n",
    "data = [r for r in data if len(r[0]) >= 200]\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstracts = [d[0] for d in data]\n",
    "titles = [d[1] for d in data]\n",
    "\n",
    "chars = []\n",
    "for abstract in abstracts:\n",
    "    for ch in abstract:\n",
    "        chars.append(ch)\n",
    "        \n",
    "chars = set(chars)\n",
    "len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts, get_tmpfile\n",
    ">>> from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'human': <gensim.models.keyedvectors.Vocab at 0x7f649dd54550>,\n",
       " 'interface': <gensim.models.keyedvectors.Vocab at 0x7f649dd54f28>,\n",
       " 'computer': <gensim.models.keyedvectors.Vocab at 0x7f649dd54518>,\n",
       " 'survey': <gensim.models.keyedvectors.Vocab at 0x7f649dd54d30>,\n",
       " 'user': <gensim.models.keyedvectors.Vocab at 0x7f649dd54588>,\n",
       " 'system': <gensim.models.keyedvectors.Vocab at 0x7f649dd54e48>,\n",
       " 'response': <gensim.models.keyedvectors.Vocab at 0x7f649dd544a8>,\n",
       " 'time': <gensim.models.keyedvectors.Vocab at 0x7f649dd54cf8>,\n",
       " 'eps': <gensim.models.keyedvectors.Vocab at 0x7f649dd54c88>,\n",
       " 'trees': <gensim.models.keyedvectors.Vocab at 0x7f649dd54b00>,\n",
       " 'graph': <gensim.models.keyedvectors.Vocab at 0x7f649dd54da0>,\n",
       " 'minors': <gensim.models.keyedvectors.Vocab at 0x7f649dd54278>}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(common_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts_split = [a.split() for a in abstracts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6382"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(abstracts_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('minors', 0.12259739637374878),\n",
       " ('trees', 0.11897511780261993),\n",
       " ('response', 0.08737078309059143),\n",
       " ('time', 0.07807287573814392),\n",
       " ('computer', 0.04872375726699829),\n",
       " ('eps', 0.04728245735168457),\n",
       " ('user', 0.011833075433969498),\n",
       " ('survey', 0.004004709422588348),\n",
       " ('interface', -0.0035754162818193436),\n",
       " ('graph', -0.005381472408771515)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Word2Vec(common_texts, size=100, window=5, min_count=1, workers=4)\n",
    "model.wv.most_similar(positive = ['human'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(abstracts_split, size = 100, window = 5,\n",
    "                               workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9282"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'A computer implemented method facilitates the capability for shop re-work orders to be effectively scheduled, knowing the time and location of item availability that is needed to correct the problem ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-dab5e3d671b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabstracts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras_preprocessing/sequence.py\u001b[0m in \u001b[0;36mpad_sequences\u001b[0;34m(sequences, maxlen, dtype, padding, truncating, value)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;31m# check `trunc` has expected shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mtrunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0msample_shape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             raise ValueError('Shape of sample %s of sequence at position %s '\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m     \"\"\"\n\u001b[0;32m--> 492\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'A computer implemented method facilitates the capability for shop re-work orders to be effectively scheduled, knowing the time and location of item availability that is needed to correct the problem "
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(num_words = 50000)\n",
    "pad_sequences(abstracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(abstracts)\n",
    "\n",
    "tokens = tokenizer.texts_to_sequences(abstracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6382"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "wtokens = pad_sequences(tokens, maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16075"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3052,  6400,     1,    48,     4,   211,     3,   467,  2253,\n",
       "          20,     8,  1581,     5,   954,     1,   334,  1372,     7,\n",
       "           1,  1192,   789,  5452,  2497,     1,    13,   270,   762,\n",
       "        2207,   302,    11,   409,    20,    32,    21,    58,     7,\n",
       "           1,  5452,  2497,     4,   115,  4138,  3636,  4139,   154,\n",
       "          20,     1,  1192,   789,  5452,  2497,    32,    21,  3052,\n",
       "         124,   302,    11,   409,    17,   120,   451,     1,    13,\n",
       "         115,   391,     5,     1,   899,  1240,    13,     5,  1192,\n",
       "        1424,   409,    37,  1783,   899,  1240,    62,    51,    24,\n",
       "           1, 11487,   899,  1894,  1240,    62,     4,   119,  2794,\n",
       "        3636,  4139,   154,    20,  1192,   789,  2497,    32,    21,\n",
       "        3052], dtype=int32)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wtokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6382, 563)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.3627121 ,  0.28522757, -1.9136485 ,  1.8326861 , -0.7968364 ,\n",
       "       -0.20501785, -0.9264961 , -1.9875044 ,  0.27362773, -0.31534263,\n",
       "        1.2691286 ,  0.6617368 ,  0.49398565,  0.05749457,  0.55550814,\n",
       "       -0.02495062, -2.2711115 , -0.5858653 , -1.3785905 ,  1.0760725 ,\n",
       "        1.5409336 , -1.6754682 , -2.5721993 , -0.37432864,  0.09750904,\n",
       "        0.45855656, -1.1702099 ,  1.507866  ,  0.8396442 ,  0.8535214 ,\n",
       "       -1.1247499 , -2.0709488 ,  1.6000314 ,  1.8581088 , -1.1098697 ,\n",
       "        0.1850865 , -2.1839714 , -1.438979  ,  1.799372  , -0.21686904,\n",
       "       -1.9578377 , -0.7918767 ,  2.4785118 , -2.4967287 ,  0.05557762,\n",
       "        0.16212144, -0.3192573 ,  0.4079158 ,  0.1613868 ,  0.08039954,\n",
       "       -1.7304522 , -2.4170291 , -0.803511  , -0.25887647,  0.03718725,\n",
       "       -0.9700573 ,  1.1086026 , -0.49431643, -0.4532563 , -0.21016037,\n",
       "       -0.67295086, -1.5961703 , -1.1284814 , -1.5268633 , -0.18875024,\n",
       "       -2.005985  ,  0.6867363 , -0.58384347,  0.7803836 , -0.49364012,\n",
       "        0.0356264 ,  0.67464143,  0.25398368, -0.8289139 , -1.2775837 ,\n",
       "        1.1192414 , -1.2858547 , -0.02700293,  1.3104949 , -0.86346394,\n",
       "        2.191672  ,  3.362186  , -0.22442524, -0.06554157, -0.9222513 ,\n",
       "       -0.4469849 , -0.74478716, -0.5369513 , -0.16541903, -0.3990541 ,\n",
       "        1.3678199 ,  0.5245562 , -0.22585584, -0.6308713 ,  0.28746507,\n",
       "        0.69488406,  0.4583291 , -1.109652  ,  1.1423215 ,  1.5182419 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.get_vector('computer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6382"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.corpus_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Word2VecVocab' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-1918b8afe84d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Word2VecVocab' object is not iterable"
     ]
    }
   ],
   "source": [
    "for x in model.vocabulary:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.05123514,  0.05868444,  0.44441643, -0.24288712, -0.46800336,\n",
       "       -0.48196575,  0.24043837, -0.17845932,  0.20962243, -0.3418752 ,\n",
       "       -0.5508718 , -0.10630816,  0.2522615 ,  0.12727764,  0.3020801 ,\n",
       "       -0.16214202, -0.22684409, -0.18211724, -0.09966335,  0.11629434,\n",
       "       -0.41902462, -0.3975493 , -0.24020046, -0.08236235,  0.16478544,\n",
       "       -0.01692858, -0.1322483 ,  0.4525788 ,  0.17023714,  0.10563406,\n",
       "       -0.17472696,  0.04847569, -0.5994605 ,  0.0663418 , -0.26894736,\n",
       "        0.15451895, -0.01773221, -0.28634632, -0.15914764,  0.2864715 ,\n",
       "        0.29430082, -0.10797698, -0.34496436, -0.25433847, -0.01160682,\n",
       "        0.06273456, -0.05913435,  0.14484854, -0.3306361 , -0.02652841,\n",
       "       -0.55654407, -0.03328067, -0.19072019, -0.0921234 ,  0.40265986,\n",
       "       -0.8008943 , -0.04934891, -0.07889152,  0.30807775, -0.34875455,\n",
       "        0.68752664,  0.45849988,  0.1568102 , -0.002287  ,  0.24896935,\n",
       "       -0.31700772,  0.22269525,  0.37641865, -0.15583992, -0.44549417,\n",
       "       -0.06447445, -0.04353243, -0.2819256 , -0.30866528,  0.31623715,\n",
       "       -0.05206877,  0.1747955 ,  0.17137936, -0.03911902, -0.3734174 ,\n",
       "        0.08411232,  0.59158117, -0.33755305, -0.31866205,  0.29169935,\n",
       "       -0.0025537 , -0.14424856, -0.07039081, -0.07636765,  0.19822696,\n",
       "       -0.48183516, -0.05771594,  0.46084216, -0.4080544 ,  0.27030334,\n",
       "       -0.4138559 ,  0.4403364 ,  0.03639235, -0.17733823, -0.09869093],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.get_vector('c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.load_model('../models/first_rnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = model.get_layer(index = 3)\n",
    "w = l.get_weights()\n",
    "len(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, None, 147)         0         \n",
      "_________________________________________________________________\n",
      "lstm_layer_0 (LSTM)          (None, None, 512)         1351680   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, None, 512)         0         \n",
      "_________________________________________________________________\n",
      "lstm_layer_1 (LSTM)          (None, None, 512)         2099200   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, None, 512)         0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, None, 147)         75411     \n",
      "=================================================================\n",
      "Total params: 3,526,291\n",
      "Trainable params: 3,526,291\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((512, 2048), (512, 2048), (2048,))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w[0].shape, w[1].shape, w[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_p36]",
   "language": "python",
   "name": "conda-env-tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
